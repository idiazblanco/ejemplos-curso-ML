{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión multivariable*\n",
    "*Ignacio Díaz Blanco, Universidad de Oviedo, 2023*\n",
    "\n",
    "\n",
    "Ejemplo básico de regresión multivariable utilizando el método `Ridge()` de `scikit-learn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de datos de ejemplo\n",
    "\n",
    "Generamos datos de ejemplo de un modelo con tres variables independientes $x_1, x_2, x_3$, un término afín independiente $b$\n",
    "$$\n",
    "y = a_1 x_1 + a_2 x_2 + a_3 x_3 + b + \\epsilon\n",
    "$$\n",
    "al cual se le ha añadido ruido de distribución normal $\\epsilon$ que representa la incertidumbre en los datos (ej. ruidos en los sensores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x1        x2        x3         y\n",
      "0    1.672715 -1.181421  0.517640  7.364000\n",
      "1   -1.341864  1.134306  1.145190 -0.465069\n",
      "2    1.320120 -0.358818 -0.366017  2.664411\n",
      "3    0.319873 -0.731434 -0.104239  2.375633\n",
      "4    0.008749 -0.397484  1.637071  6.541477\n",
      "..        ...       ...       ...       ...\n",
      "995  0.672873 -0.936985 -1.185895  0.085670\n",
      "996 -0.100822 -0.967255  0.464652  4.090283\n",
      "997 -0.016988 -1.360876  1.966611  9.845958\n",
      "998  2.763843  0.891267  1.290173  6.892364\n",
      "999  0.356819  1.215466 -1.346908 -5.374546\n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "x1 = np.random.randn(N)\n",
    "x2 = np.random.randn(N)\n",
    "x3 = np.random.randn(N)\n",
    "\n",
    "# ruido del sensor y\n",
    "epsilon = 0.2*np.random.randn(N)\n",
    "\n",
    "[a1, a2, a3, b] = [1.5, -2.1, 3.2, 0.7]\n",
    "\n",
    "X = np.column_stack((x1,x2,x3))\n",
    "y = a1*x1 + a2*x2 + a3*x3 + b + epsilon\n",
    "\n",
    "# visualizamos los datos en una tabla\n",
    "df = pd.DataFrame(np.column_stack((X,y)),columns=('x1','x2','x3','y'))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de un modelo lineal (Ridge regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         coeficientes  =  [ 1.49994676 -2.10820092  3.20129821]\n",
      "término independiente  =  0.7111290615843918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# creamos el modelo\n",
    "modelo = Ridge(alpha=0.0001)\n",
    "\n",
    "# ajustamos el modelo a los datos\n",
    "modelo.fit(X,y)\n",
    "\n",
    "# imprimimos los parámetros del modelo\n",
    "print(f'         coeficientes  =  {modelo.coef_}')\n",
    "print(f'término independiente  =  {modelo.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "los coeficientes y el término independiente se aproximan bastante bien a los reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencia del modelo y validación con los datos reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ytest     ypred     error\n",
      "0  4.828437  4.848977 -0.020540\n",
      "1  4.247320  4.259134 -0.011815\n",
      "2 -2.116932 -2.130298  0.013365\n",
      "3  1.779239  1.786552 -0.007313\n",
      "4  2.786860  2.792484 -0.005623\n",
      "5 -0.145459 -0.136832 -0.008627\n",
      "6  3.731628  3.752600 -0.020973\n",
      "7 -5.081326 -5.070455 -0.010871\n",
      "8 -1.645408 -1.635661 -0.009747\n",
      "9  1.923109  1.937196 -0.014087\n"
     ]
    }
   ],
   "source": [
    "Ntest = 10\n",
    "\n",
    "# datos de test para las tres variables independientes (sensores)\n",
    "x1test = np.random.randn(Ntest)\n",
    "x2test = np.random.randn(Ntest)\n",
    "x3test = np.random.randn(Ntest)\n",
    "\n",
    "# valores que daría el modelo ideal\n",
    "ytest = a1*x1test + a2*x2test + a3*x3test + b\n",
    "\n",
    "# datos de entrada al modelo\n",
    "Xtest = np.column_stack((x1test,x2test,x3test))\n",
    "\n",
    "# predicción del modelo\n",
    "ypred = modelo.predict(Xtest)\n",
    "\n",
    "# diferencia entre el valor ideal y la predicción\n",
    "error = ytest - ypred\n",
    "\n",
    "# mostramos los datos en una tabla\n",
    "df = pd.DataFrame(np.column_stack((ytest,ypred,error)),columns=['ytest','ypred','error'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación del modelo con la expresión matricial\n",
    "\n",
    "Estimamos el modelo utilizando la expresión\n",
    "\n",
    "$$\n",
    "\\hat {\\mathbf W} = (\\mathbf X^T \\mathbf X - \\lambda\\mathbf I)^{-1}\\mathbf X^T\\mathbf Y\n",
    "$$\n",
    "\n",
    "tomando la matriz de regresores los valores de $x$ con una columna extra de $1's$ que permite obtener el término independiente en el modelo \n",
    " \n",
    "$$\n",
    "\\mathbf X = \n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "x^1_1 & x^1_2 & x^1_3 & 1 \\\\\n",
    "x^2_1 & x^2_2 & x^2_3 & 1 \\\\\n",
    "\\vdots\\\\\n",
    "x^n_1 & x^n_2 & x^n_3 & 1 \\\\\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "\\qquad\n",
    "\\mathbf Y = \n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "y^1 \\\\\n",
    "y^2 \\\\\n",
    "\\vdots \\\\\n",
    "y^n \\\\\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "\\qquad \n",
    "{\\rm de\\; forma\\; que}\n",
    "\\qquad\n",
    "\\mathbf Y = \\mathbf X\\mathbf W\n",
    "\\qquad\n",
    "{\\rm donde}\n",
    "\\qquad\n",
    "\\mathbf W = \\left[a_1, a_2, a_3, b\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valores estimados: \n",
      "coeficientes = [[ 1.49994676 -2.10820092  3.20129821]]\n",
      "término independiente = [0.71112899]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0001\n",
    "X = np.column_stack((x1,x2,x3,np.ones(N)))\n",
    "Y = np.column_stack((y,))\n",
    "W = np.linalg.inv(X.T@X + alpha*np.eye(4))@X.T@Y\n",
    "\n",
    "# podemos obtener los coeficientes del modelo\n",
    "print('valores estimados: ')\n",
    "print(f'coeficientes = {W[:-1].T}')\n",
    "print(f'término independiente = {W[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ytest     ypred     error\n",
      "0  4.828437  4.848976 -0.020540\n",
      "1  4.247320  4.259134 -0.011815\n",
      "2 -2.116932 -2.130298  0.013365\n",
      "3  1.779239  1.786552 -0.007313\n",
      "4  2.786860  2.792484 -0.005623\n",
      "5 -0.145459 -0.136832 -0.008627\n",
      "6  3.731628  3.752600 -0.020972\n",
      "7 -5.081326 -5.070455 -0.010871\n",
      "8 -1.645408 -1.635661 -0.009747\n",
      "9  1.923109  1.937196 -0.014087\n"
     ]
    }
   ],
   "source": [
    "# datos de entrada al modelo\n",
    "Xtest = np.column_stack((x1test,x2test,x3test,np.ones(Ntest)))\n",
    "ypred = Xtest@W\n",
    "\n",
    "# diferencia entre el valor ideal y la predicción\n",
    "error = ytest - ypred.ravel()\n",
    "\n",
    "# mostramos los datos en una tabla\n",
    "df = pd.DataFrame(np.column_stack((ytest,ypred,error)),columns=['ytest','ypred','error'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sale exactamente igual.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"\"><a href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" style=\"border-width:0\"></a><br><span>Ejemplo de Regresión multivariable</span> by <a href=\"http://isa.uniovi.es/~idiaz\">Ignacio Díaz Blanco</a> is licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Reconocimiento-CompartirIgual 4.0 Internacional License</a>.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curso_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
